#!/usr/bin/env python3
"""
ìƒíƒœê³„ JSON íŒŒì„œ with ì¬ì‹œì‘ ë¶ë§ˆí¬ ê¸°ëŠ¥
- result/Json ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ìƒíƒœê³„ íŒŒì¼ì„ ìˆœì°¨ ì²˜ë¦¬
- ì¤‘ë‹¨ì ì—ì„œ ì¬ì‹œì‘ ê°€ëŠ¥í•œ ë¶ë§ˆí¬ ì‹œìŠ¤í…œ
- ì§„í–‰ìƒí™© ìë™ ì €ì¥ ë° ë³µì›
- ì‘ì„±: 2025-08-11
"""
import json
import os
import time
import logging
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional
from pathlib import Path
from tqdm import tqdm
import mysql.connector
from mysql.connector import Error
from contextlib import contextmanager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')

# ì„¤ì •
JSON_INPUT_DIR = "../../result/Json"
BOOKMARK_FILE = "ecosystem_parser_bookmark.json"
MAX_WORKERS = 4
BATCH_SIZE = 1000
PROGRESS_INTERVAL = 10000
AUTO_SAVE_INTERVAL = 50000  # 5ë§Œê°œë§ˆë‹¤ ë¶ë§ˆí¬ ì €ì¥

# MariaDB ì—°ê²° ì„¤ì •
DB_CONFIG = {
    'host': 'localhost',
    'database': 'package_parser_db',
    'user': 'fortify',
    'password': 'Fortify!234',
    'charset': 'utf8mb4',
    'autocommit': False
}

# ìƒíƒœê³„ë³„ í…Œì´ë¸” ë§¤í•‘
ECOSYSTEM_TABLES = {
    'npm': {'packages': 'npm_packages', 'versions': 'npm_package_versions'},
    'pypi': {'packages': 'pypi_packages', 'versions': 'pypi_package_versions'},
    'maven': {'packages': 'maven_packages', 'versions': 'maven_package_versions'},
    'nuget': {'packages': 'nuget_packages', 'versions': 'nuget_package_versions'},
    'go': {'packages': 'go_packages', 'versions': 'go_package_versions'},
    'rubygems': {'packages': 'rubygems_packages', 'versions': 'rubygems_package_versions'},
    'cargo': {'packages': 'cargo_packages', 'versions': 'cargo_package_versions'}
}

# ê¸€ë¡œë²Œ ë³€ìˆ˜
current_bookmark = {}
db_lock = threading.Lock()

@contextmanager
def get_db_connection():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•©ë‹ˆë‹¤."""
    connection = None
    try:
        connection = mysql.connector.connect(**DB_CONFIG)
        yield connection
    except Error as e:
        logging.error(f"Database connection error: {e}")
        if connection:
            connection.rollback()
        raise
    finally:
        if connection and connection.is_connected():
            connection.close()

def load_bookmark() -> Dict[str, Any]:
    """ì €ì¥ëœ ë¶ë§ˆí¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if os.path.exists(BOOKMARK_FILE):
        try:
            with open(BOOKMARK_FILE, 'r', encoding='utf-8') as f:
                bookmark = json.load(f)
                logging.info(f"ğŸ“– ë¶ë§ˆí¬ ë¡œë“œë¨: {bookmark.get('last_saved', 'Unknown')}")
                logging.info(f"   ë§ˆì§€ë§‰ ì²˜ë¦¬: {bookmark.get('last_ecosystem', 'None')}")
                logging.info(f"   ë§ˆì§€ë§‰ íŒŒì¼: {bookmark.get('last_file', 'None')}")
                logging.info(f"   ì²˜ë¦¬ëœ íŒ¨í‚¤ì§€: {bookmark.get('total_processed', 0):,}ê°œ")
                return bookmark
        except Exception as e:
            logging.warning(f"ë¶ë§ˆí¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return {
        'completed_ecosystems': [],
        'completed_files': [],
        'current_ecosystem': None,
        'current_file': None,
        'current_file_position': 0,
        'total_processed': 0,
        'total_saved': 0,
        'start_time': time.time(),
        'last_saved': time.strftime('%Y-%m-%d %H:%M:%S')
    }

def save_bookmark(bookmark: Dict[str, Any]):
    """í˜„ì¬ ì§„í–‰ìƒí™©ì„ ë¶ë§ˆí¬ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    global current_bookmark
    bookmark['last_saved'] = time.strftime('%Y-%m-%d %H:%M:%S')
    
    try:
        with open(BOOKMARK_FILE, 'w', encoding='utf-8') as f:
            json.dump(bookmark, f, ensure_ascii=False, indent=2)
        current_bookmark = bookmark.copy()
        logging.info(f"ğŸ’¾ ë¶ë§ˆí¬ ì €ì¥ë¨: {bookmark['total_processed']:,}ê°œ ì²˜ë¦¬ë¨")
    except Exception as e:
        logging.error(f"ë¶ë§ˆí¬ ì €ì¥ ì‹¤íŒ¨: {e}")

def should_skip_ecosystem(ecosystem: str, bookmark: Dict[str, Any]) -> bool:
    """ì´ë¯¸ ì™„ë£Œëœ ìƒíƒœê³„ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return ecosystem in bookmark.get('completed_ecosystems', [])

def should_skip_file(file_path: str, bookmark: Dict[str, Any]) -> bool:
    """ì´ë¯¸ ì™„ë£Œëœ íŒŒì¼ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return file_path in bookmark.get('completed_files', [])

def detect_ecosystem(filename: str) -> str:
    """íŒŒì¼ëª…ì—ì„œ ìƒíƒœê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    filename_lower = filename.lower()
    
    if 'npm' in filename_lower:
        return 'npm'
    elif 'pypi' in filename_lower:
        return 'pypi'
    elif 'maven' in filename_lower:
        return 'maven'
    elif 'nuget' in filename_lower:
        return 'nuget'
    elif 'go' in filename_lower:
        return 'go'
    elif 'rubygems' in filename_lower:
        return 'rubygems'
    elif 'cargo' in filename_lower:
        return 'cargo'
    else:
        return 'unknown'

def find_json_files() -> Dict[str, List[str]]:
    """Json ë””ë ‰í† ë¦¬ì—ì„œ ìƒíƒœê³„ë³„ íŒŒì¼ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤."""
    input_path = Path(JSON_INPUT_DIR)
    
    if not input_path.exists():
        logging.error(f"Input directory not found: {JSON_INPUT_DIR}")
        return {}
    
    ecosystem_files = {}
    
    for file_path in input_path.glob("*.json"):
        ecosystem = detect_ecosystem(file_path.name)
        if ecosystem != 'unknown':
            ecosystem_files.setdefault(ecosystem, []).append(str(file_path))
    
    # íŒŒì¼ í¬ê¸° ìˆœìœ¼ë¡œ ì •ë ¬ (ì‘ì€ ê²ƒë¶€í„°)
    for ecosystem in ecosystem_files:
        ecosystem_files[ecosystem].sort(key=lambda x: os.path.getsize(x))
    
    total_files = sum(len(files) for files in ecosystem_files.values())
    logging.info(f"Found {total_files} JSON files across {len(ecosystem_files)} ecosystems")
    
    for ecosystem, files in ecosystem_files.items():
        total_size = sum(os.path.getsize(f) for f in files)
        logging.info(f"  {ecosystem.upper()}: {len(files)} files ({total_size/1024/1024:.1f} MB)")
    
    return ecosystem_files

def parse_json_file_with_bookmark(file_path: str, ecosystem: str, bookmark: Dict[str, Any]) -> Dict[str, Any]:
    """ë¶ë§ˆí¬ ì§€ì›ìœ¼ë¡œ JSON íŒŒì¼ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
    try:
        file_size = os.path.getsize(file_path)
        file_name = os.path.basename(file_path)
        start_position = 0
        
        # ë¶ë§ˆí¬ì—ì„œ ì‹œì‘ ìœ„ì¹˜ í™•ì¸
        if (bookmark.get('current_file') == file_path and 
            bookmark.get('current_ecosystem') == ecosystem):
            start_position = bookmark.get('current_file_position', 0)
            if start_position > 0:
                logging.info(f"ğŸ“ ì¬ì‹œì‘: {file_name} (ìœ„ì¹˜: {start_position:,})")
        
        logging.info(f"Processing {file_name} ({file_size / 1024 / 1024:.1f} MB)")
        
        packages = []
        processed_count = 0
        
        with open(file_path, 'r', encoding='utf-8') as f:
            # í° íŒŒì¼ì˜ ê²½ìš° í•œ ì¤„ì”© ì½ê¸°
            if file_size > 100 * 1024 * 1024:  # 100MB ì´ìƒ
                logging.info(f"Large file detected, reading line by line: {file_name}")
                
                for line_num, line in enumerate(f):
                    # ì‹œì‘ ìœ„ì¹˜ ìŠ¤í‚µ
                    if line_num < start_position:
                        continue
                        
                    line = line.strip()
                    if line and not line.startswith('[') and not line.startswith(']'):
                        if line.endswith(','):
                            line = line[:-1]
                        try:
                            package = json.loads(line)
                            packages.append(package)
                            processed_count += 1
                            
                            # ìë™ ì €ì¥ ê°„ê²©ë§ˆë‹¤ ë¶ë§ˆí¬ ì—…ë°ì´íŠ¸
                            if processed_count % AUTO_SAVE_INTERVAL == 0:
                                bookmark.update({
                                    'current_ecosystem': ecosystem,
                                    'current_file': file_path,
                                    'current_file_position': line_num + 1,
                                    'total_processed': bookmark.get('total_processed', 0) + processed_count
                                })
                                save_bookmark(bookmark)
                                
                                # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´ ë°°ì¹˜ ì €ì¥
                                if packages:
                                    saved_count = save_packages_to_db(packages, ecosystem)
                                    bookmark['total_saved'] = bookmark.get('total_saved', 0) + saved_count
                                    packages = []  # ë©”ëª¨ë¦¬ í•´ì œ
                                    logging.info(f"  ğŸ’¾ ì¤‘ê°„ ì €ì¥: {saved_count:,}ê°œ (ëˆ„ì : {bookmark['total_saved']:,}ê°œ)")
                            
                            if processed_count % PROGRESS_INTERVAL == 0:
                                logging.info(f"  Processed {processed_count:,} packages from {file_name}")
                                
                        except json.JSONDecodeError:
                            continue
            else:
                # ì‘ì€ íŒŒì¼ì€ ì¼ë°˜ì ì¸ ë°©ì‹ìœ¼ë¡œ ì½ê¸°
                content = f.read().strip()
                if content.startswith('[') and content.endswith(']'):
                    packages = json.loads(content)
                else:
                    for line in content.split('\n'):
                        line = line.strip()
                        if line and line != ',' and not line.startswith('[') and not line.startswith(']'):
                            if line.endswith(','):
                                line = line[:-1]
                            try:
                                package = json.loads(line)
                                packages.append(package)
                            except json.JSONDecodeError:
                                continue
        
        logging.info(f"Parsed {len(packages):,} packages from {file_name}")
        
        return {
            'file_path': file_path,
            'file_name': file_name,
            'ecosystem': ecosystem,
            'package_count': len(packages),
            'packages': packages,
            'success': True
        }
        
    except Exception as e:
        error_msg = f"Error parsing {file_path}: {str(e)}"
        logging.error(error_msg)
        return {
            'file_path': file_path,
            'file_name': os.path.basename(file_path),
            'ecosystem': ecosystem,
            'error': error_msg,
            'success': False
        }

def save_packages_to_db(packages_data: List[Dict[str, Any]], ecosystem: str) -> int:
    """íŒ¨í‚¤ì§€ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
    if not packages_data or ecosystem not in ECOSYSTEM_TABLES:
        return 0
    
    tables = ECOSYSTEM_TABLES[ecosystem]
    packages_table = tables['packages']
    versions_table = tables['versions']
    
    saved_count = 0
    
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            for i in range(0, len(packages_data), BATCH_SIZE):
                batch = packages_data[i:i + BATCH_SIZE]
                
                for package in batch:
                    try:
                        name = package.get('Name', '').strip()
                        versions = package.get('Versions', [])
                        
                        if not name or not versions:
                            continue
                        
                        # íŒ¨í‚¤ì§€ ì‚½ì…/ì—…ë°ì´íŠ¸
                        if ecosystem == 'maven':
                            parts = name.split(':')
                            if len(parts) >= 2:
                                group_id = parts[0]
                                artifact_id = parts[1]
                                
                                package_sql = f"""
                                INSERT INTO {packages_table} (name, group_id, artifact_id)
                                VALUES (%s, %s, %s)
                                ON DUPLICATE KEY UPDATE updated_at = CURRENT_TIMESTAMP
                                """
                                cursor.execute(package_sql, (name, group_id, artifact_id))
                            else:
                                continue
                        else:
                            package_sql = f"""
                            INSERT INTO {packages_table} (name)
                            VALUES (%s)
                            ON DUPLICATE KEY UPDATE updated_at = CURRENT_TIMESTAMP
                            """
                            cursor.execute(package_sql, (name,))
                        
                        # íŒ¨í‚¤ì§€ ID ê°€ì ¸ì˜¤ê¸°
                        package_id = cursor.lastrowid
                        if not package_id:
                            cursor.execute(f"SELECT id FROM {packages_table} WHERE name = %s", (name,))
                            result = cursor.fetchone()
                            package_id = result[0] if result else None
                        
                        if package_id and versions:
                            cursor.execute(f"DELETE FROM {versions_table} WHERE package_id = %s", (package_id,))
                            
                            version_data = [
                                (package_id, str(version)[:500])  # ë²„ì „ ê¸¸ì´ ì œí•œ
                                for version in versions
                                if version and str(version).strip()
                            ]
                            
                            if version_data:
                                version_sql = f"INSERT INTO {versions_table} (package_id, version) VALUES (%s, %s)"
                                cursor.executemany(version_sql, version_data)
                        
                        saved_count += 1
                        
                    except Error as e:
                        logging.warning(f"Failed to save package {package.get('Name', 'unknown')} in {ecosystem}: {e}")
                        continue
                
                conn.commit()
            
    except Error as e:
        logging.error(f"Database error while saving {ecosystem} packages: {e}")
        
    return saved_count

def process_ecosystem_with_bookmark(ecosystem: str, file_paths: List[str], bookmark: Dict[str, Any]) -> Dict[str, Any]:
    """ë¶ë§ˆí¬ ì§€ì›ìœ¼ë¡œ íŠ¹ì • ìƒíƒœê³„ì˜ ëª¨ë“  íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    if should_skip_ecosystem(ecosystem, bookmark):
        logging.info(f"â­ï¸  {ecosystem.upper()} ìƒíƒœê³„ ì´ë¯¸ ì™„ë£Œë¨ - ìŠ¤í‚µ")
        return {'ecosystem': ecosystem, 'skipped': True}
    
    logging.info(f"\nğŸŒ Processing {ecosystem.upper()} ecosystem ({len(file_paths)} files)...")
    
    start_time = time.time()
    total_packages = 0
    total_saved = 0
    processed_files = 0
    failed_files = 0
    
    for file_path in file_paths:
        if should_skip_file(file_path, bookmark):
            logging.info(f"â­ï¸  {os.path.basename(file_path)} ì´ë¯¸ ì™„ë£Œë¨ - ìŠ¤í‚µ")
            continue
            
        try:
            # íŒŒì¼ íŒŒì‹±
            result = parse_json_file_with_bookmark(file_path, ecosystem, bookmark)
            
            if result['success']:
                packages = result['packages']
                if packages:
                    saved_count = save_packages_to_db(packages, ecosystem)
                    total_saved += saved_count
                    total_packages += len(packages)
                
                processed_files += 1
                
                # íŒŒì¼ ì™„ë£Œ í›„ ë¶ë§ˆí¬ ì—…ë°ì´íŠ¸
                bookmark.setdefault('completed_files', []).append(file_path)
                bookmark['total_processed'] = bookmark.get('total_processed', 0) + len(packages)
                bookmark['total_saved'] = bookmark.get('total_saved', 0) + saved_count
                bookmark['current_file_position'] = 0  # íŒŒì¼ ì™„ë£Œ ì‹œ ìœ„ì¹˜ ë¦¬ì…‹
                save_bookmark(bookmark)
                
                logging.info(f"  âœ… {result['file_name']}: {len(packages):,} packages â†’ {saved_count:,} saved")
            else:
                failed_files += 1
                logging.error(f"  âŒ {result['file_name']}: {result.get('error', 'Unknown error')}")
                
        except KeyboardInterrupt:
            logging.info(f"\nâš ï¸  ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ - ë¶ë§ˆí¬ ì €ì¥ ì¤‘...")
            save_bookmark(bookmark)
            logging.info(f"ğŸ’¾ ì§„í–‰ìƒí™©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì´ì–´ì„œ ê³„ì†ë©ë‹ˆë‹¤.")
            raise
        except Exception as e:
            failed_files += 1
            logging.error(f"  âŒ {os.path.basename(file_path)}: {str(e)}")
    
    # ìƒíƒœê³„ ì™„ë£Œ í›„ ë¶ë§ˆí¬ ì—…ë°ì´íŠ¸
    bookmark.setdefault('completed_ecosystems', []).append(ecosystem)
    save_bookmark(bookmark)
    
    elapsed_time = time.time() - start_time
    
    summary = {
        'ecosystem': ecosystem,
        'processed_files': processed_files,
        'failed_files': failed_files,
        'total_packages': total_packages,
        'total_saved': total_saved,
        'processing_time': elapsed_time,
        'success_rate': (total_saved / total_packages * 100) if total_packages > 0 else 0
    }
    
    logging.info(f"ğŸ¯ {ecosystem.upper()} Summary:")
    logging.info(f"  Files: {processed_files}/{len(file_paths)} processed")
    logging.info(f"  Packages: {total_saved:,}/{total_packages:,} saved ({summary['success_rate']:.1f}%)")
    logging.info(f"  Time: {elapsed_time:.1f}s")
    
    return summary

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    global current_bookmark
    
    logging.info("ğŸš€ Starting Ecosystem Parser with Resume Support...")
    
    # ë¶ë§ˆí¬ ë¡œë“œ
    bookmark = load_bookmark()
    current_bookmark = bookmark
    
    # ì‚¬ìš©ìì—ê²Œ ì¬ì‹œì‘ ì˜µì…˜ ì œê³µ
    if bookmark.get('total_processed', 0) > 0:
        print(f"\nğŸ“– ì´ì „ ì§„í–‰ìƒí™© ë°œê²¬:")
        print(f"   ì²˜ë¦¬ëœ íŒ¨í‚¤ì§€: {bookmark['total_processed']:,}ê°œ")
        print(f"   ì €ì¥ëœ íŒ¨í‚¤ì§€: {bookmark.get('total_saved', 0):,}ê°œ")
        print(f"   ì™„ë£Œëœ ìƒíƒœê³„: {len(bookmark.get('completed_ecosystems', []))}ê°œ")
        print(f"   ë§ˆì§€ë§‰ ì €ì¥: {bookmark.get('last_saved', 'Unknown')}")
        
        choice = input("\nê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n, ê¸°ë³¸ê°’=y): ").strip().lower()
        if choice == 'n':
            # ìƒˆë¡œ ì‹œì‘
            bookmark = {
                'completed_ecosystems': [],
                'completed_files': [],
                'current_ecosystem': None,
                'current_file': None,
                'current_file_position': 0,
                'total_processed': 0,
                'total_saved': 0,
                'start_time': time.time(),
                'last_saved': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            save_bookmark(bookmark)
            logging.info("ğŸ”„ ìƒˆë¡œìš´ íŒŒì‹± ì„¸ì…˜ ì‹œì‘...")
    
    try:
        # JSON íŒŒì¼ë“¤ ì°¾ê¸°
        ecosystem_files = find_json_files()
        if not ecosystem_files:
            logging.error("No JSON files found. Exiting.")
            return
        
        overall_start_time = time.time()
        all_summaries = []
        
        # ìƒíƒœê³„ë³„ ìˆœì°¨ ì²˜ë¦¬
        for ecosystem, file_paths in ecosystem_files.items():
            try:
                summary = process_ecosystem_with_bookmark(ecosystem, file_paths, bookmark)
                if not summary.get('skipped'):
                    all_summaries.append(summary)
            except KeyboardInterrupt:
                logging.info("\nâš ï¸  í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return
            except Exception as e:
                logging.error(f"Failed to process {ecosystem}: {e}")
                continue
        
        # ì „ì²´ ì™„ë£Œ ì‹œ ë¶ë§ˆí¬ ì‚­ì œ
        if os.path.exists(BOOKMARK_FILE):
            os.remove(BOOKMARK_FILE)
            logging.info("ğŸ—‘ï¸  ëª¨ë“  ì‘ì—… ì™„ë£Œ - ë¶ë§ˆí¬ íŒŒì¼ ì‚­ì œë¨")
        
        # ì „ì²´ ìš”ì•½
        overall_time = time.time() - overall_start_time
        total_files = sum(s.get('processed_files', 0) + s.get('failed_files', 0) for s in all_summaries)
        total_packages = sum(s.get('total_packages', 0) for s in all_summaries)
        total_saved = sum(s.get('total_saved', 0) for s in all_summaries)
        
        logging.info(f"\n" + "="*60)
        logging.info(f"ğŸ‰ ECOSYSTEM PARSING COMPLETE!")
        logging.info(f"="*60)
        logging.info(f"ğŸ“Š Overall Statistics:")
        logging.info(f"  Ecosystems: {len(all_summaries)}")
        logging.info(f"  Files: {total_files}")
        logging.info(f"  Packages: {total_saved:,}/{total_packages:,} saved ({total_saved/total_packages*100:.1f}%)")
        logging.info(f"  Time: {overall_time:.1f}s")
        
        logging.info(f"\nğŸ“‹ Ecosystem Breakdown:")
        for summary in sorted(all_summaries, key=lambda x: x.get('total_saved', 0), reverse=True):
            logging.info(f"  {summary['ecosystem'].upper()}: {summary.get('total_saved', 0):,} packages")
    
    except KeyboardInterrupt:
        logging.info(f"\nâš ï¸  í”„ë¡œê·¸ë¨ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        logging.info(f"ğŸ’¾ ë‹¤ìŒ ì‹¤í–‰ ì‹œ '{BOOKMARK_FILE}' íŒŒì¼ë¡œë¶€í„° ì´ì–´ì„œ ê³„ì†ë©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()